# -*- coding: utf-8 -*-
"""01-Data cleaning-ta1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QmILb_ARoqflc_AK9LWaqvlL0BzJLLAM#scrollTo=I7VSVjnvQegf"""

# 1. import libraries
import pandas as pd
import pycountry  
import matplotlib.pyplot as plt
import seaborn as sns

# 2.  load dataset

df = pd.read_excel("data/custom-import-data.xlsx")
print(df.head())


"""## Rename columns headers"""

df = df.rename(columns={
    "Custom Office": "Custom_office",
    "Reg Number": "Reg_number",
    "Importer": "Importer",
    "HS Code": "HS_code",
    "FOB Value (N)": "FOB_value($)",
    "CIF Value (N)": "CIF_value($)",
    "Total Tax(N)": "Total_Tax($)",
    "Receipt Number": "Receipt_number",
    "Receipt Date": "Receipt_date",
    "Mass(KG)": "Mass_(kg)",
    "Country  of Origin": "Country_of_origin",
    "Country  of Supply": "Country_of_supply",
    "Nbr Of Containers": "Nbr_of_containers",
    "Container Nbr":"Container_nbr",
    "Container Size":"Container_size"
})

# 4. Inspect dataset

# check first 10 rows

df.head(10)

## check size
df.shape

## check more information

df.info()

## Basic summary

df.describe()

## Convert identifiers to object datatype

# confirm datatypes again

df.info()

## Handling missing values

#get number of missing values

df.isnull().sum()

#percentage of missing values

df.isnull().sum() / len(df) * 100

#### For missing number

# Forward fill missing values for Receipt Number
df['Receipt_number'] = df['Receipt_number'].ffill()

# Check again
print(df['Receipt_number'].isnull().sum())

#### fill null values in country of supply with country of origin

# Fill missing Country of Supply with Country of Origin values
df['Country_of_supply'] = df['Country_of_supply'].fillna(df['Country_of_origin'])

# Check again
print(df['Country_of_supply'].isnull().sum())

"""#### Confirm  the unique values in country of origin and country of supply"""

# Unique values in Country of Origin
print("Country_of_origin unique values:\n", df['Country_of_origin'].unique())

# Unique values in Country of Supply
print("\nCountry_of_supply unique values:\n", df['Country_of_supply'].unique())

"""#### Standardize the countries in these columns : country of origin and country of supply"""

# Function to standardize country names

def standardize_country(name):
    try:
        return pycountry.countries.lookup(str(name)).name
    except:
        return "Unknown"

# Standardize both columns
df["Country_of_origin"] = df["Country_of_origin"].apply(standardize_country)
df["Country_of_supply"] = df["Country_of_supply"].apply(standardize_country)

# If supply is Unknown but origin is valid → copy origin
df.loc[(df["Country_of_supply"] == "Unknown") & (df["Country_of_origin"] != "Unknown"),
       "Country_of_supply"] = df["Country_of_origin"]

# If origin is Unknown but supply is valid → copy supply
df.loc[(df["Country_of_origin"] == "Unknown") & (df["Country_of_supply"] != "Unknown"),
       "Country_of_origin"] = df["Country_of_supply"]

# Check the results
print("Unique Origin Countries:", df["Country_of_origin"].unique())
print("\nUnique Supply Countries:", df["Country_of_supply"].unique())

# Check if "Unknown" is in each column

print(df["Country_of_origin"].isin(["Unknown"]).any())

print(df["Country_of_supply"].isin(["Unknown"]).any())

# If True, also show how many rows are marked Unknown

print("\nCount of 'Unknown' in Origin:", (df["Country_of_origin"] == "Unknown").sum())

print("Count of 'Unknown' in Supply:", (df["Country_of_supply"] == "Unknown").sum())

#### check the percentage of unknown

# percentage of 'Unknown' in Origin
perc_origin_unknown = (df["Country_of_origin"].eq("Unknown").sum() / len(df)) * 100

# percentage of 'Unknown' in Supply
perc_supply_unknown = (df["Country_of_supply"].eq("Unknown").sum() / len(df)) * 100

print(f"Origin Unknown: {perc_origin_unknown:.2f}%")
print(f"Supply Unknown: {perc_supply_unknown:.2f}%")

### For missing values in Container_Nbr

# fill missing values for Container_nbr with "Unknown"

df["Container_nbr"] = df["Container_nbr"].fillna("Unknown")

"""### For Missing values in Container_size

#### There is some relationship between mass, country of of origin and country of supply, lets check it out
"""

# filter rows where Mass is not null
has_mass = df[df["Mass_(kg)"].notna()]

# count how many have origin == supply
same_country = (has_mass["Country_of_origin"] == has_mass["Country_of_supply"]).sum()

# total with mass
total_mass = len(has_mass)

# percentage
percentage_same = same_country / total_mass * 100

print(f"Total with Mass: {total_mass}")
print(f"Origin == Supply when Mass present: {same_country} ({percentage_same:.2f}%)")

## Where mass is not null and country of origin is equal to country of supply, fill with the most common container size, if not fill with "Unknown"


# find the most common size overall
common_size = df['Container_size'].mode()[0]

# fill missing container_size under the condition
mask = df['Container_size'].isna() & df['Mass_(kg)'].notna() & (df['Country_of_origin'] == df['Country_of_supply'])
df.loc[mask, 'Container_size'] = common_size

# any other missing values → Unknown
df['Container_size'] = df['Container_size'].fillna("Unknown")

# check sum of missing values again
df.isnull().sum()

## cleaning the Receipt_date

# 1. Convert to datetime
df['Receipt_date'] = pd.to_datetime(df['Receipt_date'], errors='coerce')

# 2. Forward fill missing dates
df['Receipt_date'] = df['Receipt_date'].ffill()

# 3. Fix wrong years
year_map = {1866: 2022, 1867: 2023, 1868: 2024, 1869: 2025}
df['Receipt_date'] = df['Receipt_date'].apply(
    lambda x: x.replace(year=year_map[x.year]) if pd.notnull(x) and x.year in year_map else x
)

# 4. Extract year into one column
df['Year'] = df['Receipt_date'].dt.year

df.info()

# Check result
df.head(10)

# Check unique years
unique_years = df['Year'].unique()

print(unique_years)

#confirm there is no missing values
df.isnull().sum()

## convert unique identifiers to Objects


df[["Unnamed: 0", "Importer", "HS_code"]] = df[["Unnamed: 0", "Importer", "HS_code"]].astype(str)

df.info()

# extract Chapters
df["Chapter"] = df["HS_code"].str[:2].astype(int)
df.head(10)

#section mapping
sections = [
    (range(1, 6), "I", "Live animals; animal products"),
    (range(6, 15), "II", "Vegetable products"),
    (range(15, 16), "III", "Animal or vegetable fats and oils"),
    (range(16, 25), "IV", "Prepared foodstuffs; beverages; tobacco"),
    (range(25, 28), "V", "Mineral products"),
    (range(28, 39), "VI", "Chemicals and allied industries"),
    (range(39, 41), "VII", "Plastics, rubber"),
    (range(41, 44), "VIII", "Hides, skins, leather, furs"),
    (range(44, 50), "IX", "Wood and articles of wood"),
    (range(50, 64), "XI", "Textiles and textile articles"),
    (range(64, 68), "XII", "Footwear, headgear, umbrellas"),
    (range(68, 71), "XIII", "Articles of stone, plaster, cement, glass"),
    (range(71, 72), "XIV", "Pearls, precious stones and metals"),
    (range(72, 84), "XV", "Base metals and articles of base metal"),
    (range(84, 86), "XVI", "Machinery and mechanical appliances"),
    (range(86, 90), "XVII", "Vehicles, aircraft, vessels"),
    (range(90, 93), "XVIII", "Optical, photographic, measuring instruments"),
    (range(93, 97), "XIX", "Arms and ammunition"),
    (range(97, 98), "XX", "Works of art, collectors pieces, antiques"),
    (range(98, 100), "XXI", "Miscellaneous goods")
]

# Function to map chapter to section
def get_section(chapter):
    for r, sec, name in sections:
        if chapter in r:
            return sec, name
    return "Unknown", "Unknown"

# Apply mapping
df[["section", "section_name"]] = df["Chapter"].apply(lambda x: pd.Series(get_section(x)))

df.head(10)

# Get the list of columns
cols = list(df.columns)

# Find the position of hs_code column
hs_pos = cols.index("HS_code")

# Reorder: put hs_code, chapter, section, Section_name right after hs_code
new_order = cols[:hs_pos+1] + ["Chapter", "section", "section_name"] + cols[hs_pos+1:-3]

# Reassign
df = df[new_order]

# Now df will show chapter and section right beside hs_code
df.head()

# convert chapter to object
df["Chapter"] = df["Chapter"].astype(str)

df.info()

# Detect outliers using IQR
def detect_outliers_iqr(df, cols):
    summary = []
    for col in cols:
        s = df[col].dropna()
        Q1 = s.quantile(0.25)
        Q3 = s.quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        mask = (df[col] < lower) | (df[col] > upper)
        df[f'{col}_outlier_iqr'] = mask
        summary.append({
            'col': col,
            'count_outliers': int(mask.sum()),
            'pct_outliers': float(mask.mean()*100),
            'lower': lower,
            'upper': upper
        })
    return pd.DataFrame(summary)

# Define the list of numeric columns to check for outliers
numeric_cols = ["FOB_value($)", "CIF_value($)", "Total_Tax($)", "Mass_(kg)", "Nbr_of_containers"]

outlier_summary = detect_outliers_iqr(df, numeric_cols)
print(outlier_summary)

# convert to catergorical data
df["Year"] = df["Year"].astype(str)

# plot outliners by year

for col in numeric_cols:
    plt.figure(figsize=(10, 4))
    sns.boxplot(
        x="Year",
        y=col,
        data=df,
        palette="viridis",
        hue="Year"  # add hue to color by year
    )
    plt.title(f"{col} by Year")
    plt.legend(title="Year", bbox_to_anchor=(1.05, 1), loc="upper left") # move legend aside
    plt.show()

df.to_csv(r"C:\Users\HP\Desktop\Trade&Customs-ta1-project\data\cleaned_Trade&Customs_data.csv", index=False)
print("Cleaning done,csv saved.")